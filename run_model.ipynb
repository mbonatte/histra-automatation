{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aaef49c",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccf3bbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99ca87e",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdd080db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Base units ===\n",
    "kN = 1.0\n",
    "N = kN / 1000\n",
    "cm = 1.0\n",
    "m = cm * 100\n",
    "\n",
    "# === Derived geometry ===\n",
    "cm2 = cm**2\n",
    "m2 = m**2\n",
    "cm3 = cm**3\n",
    "m3 = m**3\n",
    "\n",
    "# === Line load ===\n",
    "kN_per_m = kN / m\n",
    "\n",
    "# === Pressure ===\n",
    "Pa  = N / m2\n",
    "kPa = 1e3 * Pa\n",
    "MPa = 1e6 * Pa\n",
    "GPa = 1e9 * Pa\n",
    "\n",
    "# === Volumetric (density, unit weight, etc.) ===\n",
    "kN_per_m3 = kN / m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92c296a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10 * MPa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d44235",
   "metadata": {},
   "source": [
    "# Main parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a73fa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from plot_results import flat_data\n",
    "\n",
    "# with open(\"scenarios_results.json\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# df = flat_data(data).drop([], axis=1)\n",
    "# colu = df.drop(\n",
    "#     [c for c in df.columns if c.endswith(\"Key\")]\n",
    "#     + [c for c in df.columns if c.startswith(\"Deleted_layer\")]\n",
    "#     + [c for c in df.columns if c.startswith((\"Ux\", \"Uy\", \"Uz\", \"R1\", \"R2\", \"R3\"))]\n",
    "#     + [\"Analysis\", \"_source_index\"],\n",
    "#     axis=1,\n",
    "# )\n",
    "\n",
    "# colu.describe().iloc[:, :20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c16eb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ranges = {}\n",
    "\n",
    "# Parameter ranges (min, max)\n",
    "param_ranges.update({\n",
    "    \"Foundation_w\": (10 * kN_per_m3, 40 * kN_per_m3),\n",
    "    \"Foundation_Ehor\": (1 * GPa, 30 * GPa),\n",
    "\n",
    "    \"Foundation_FtmHor\": (0.01 * MPa, 4 * MPa),\n",
    "    \"Foundation_Gt\": (0.001 * kN_per_m, 0.1 * kN_per_m),\n",
    "    \n",
    "    \"Foundation_FmHor\": (1 * MPa, 40 * MPa),\n",
    "    \"Foundation_Gc\": (0.1 * kN_per_m, 10 * kN_per_m),\n",
    "\n",
    "    \"Foundation_Gd\": (0.5 * GPa, 15 * GPa),\n",
    "\n",
    "    \"Foundation_fvk0d\": (0.001 * MPa, 1 * MPa),\n",
    "    \"Foundation_FrictionRatioShear\": (0.2, 1),\n",
    "    \"Foundation_ShearMaxTensileRatio\": (0.3, 0.8),\n",
    "    \n",
    "    \"Foundation_CohesionSlidingHor\": (0.001 * MPa, 1 * MPa),\n",
    "    \"Foundation_FrictionRatioSlidingHor\": (0.1, 1.2),\n",
    "})\n",
    "\n",
    "param_ranges.update({\n",
    "    \"Masonry_w\": (10 * kN_per_m3, 40 * kN_per_m3),\n",
    "    \"Masonry_Ehor\": (1 * GPa, 30 * GPa),\n",
    "\n",
    "    \"Masonry_FtmHor\": (0.01 * MPa, 4 * MPa),\n",
    "    \"Masonry_Gt\": (0.001 * kN_per_m, 0.1 * kN_per_m),\n",
    "    \n",
    "    \"Masonry_FmHor\": (1 * MPa, 40 * MPa),\n",
    "    \"Masonry_Gc\": (0.1 * kN_per_m, 10 * kN_per_m),\n",
    "\n",
    "    \"Masonry_Gd\": (0.5 * GPa, 15 * GPa),\n",
    "\n",
    "    \"Masonry_fvk0d\": (0.001 * MPa, 1 * MPa),\n",
    "    \"Masonry_FrictionRatioShear\": (0.2, 1),\n",
    "    \"Masonry_ShearMaxTensileRatio\": (0.3, 0.8),\n",
    "    \n",
    "    \"Masonry_CohesionSlidingHor\": (0.001 * MPa, 1 * MPa),\n",
    "    \"Masonry_FrictionRatioSlidingHor\": (0.1, 1.2),\n",
    "})\n",
    "\n",
    "param_ranges.update({\n",
    "    \"Backfill_w\": (10 * kN_per_m3, 30 * kN_per_m3),\n",
    "    \"Backfill_Ehor\": (0.001 * GPa, 4 * GPa),\n",
    "\n",
    "    \"Backfill_FtmHor\": (0.0001 * kPa, 1000 * kPa),\n",
    "    \"Backfill_Gt\": (0.001 * kN_per_m, 0.1 * kN_per_m),\n",
    "    \n",
    "    \"Backfill_FmHor\": (0.1 * MPa, 10 * MPa),\n",
    "    \"Backfill_Gc\": (0.1 * kN_per_m, 10 * kN_per_m),\n",
    "\n",
    "    \"Backfill_Gd\": (0.0005 * GPa, 2 * GPa),\n",
    "\n",
    "    \"Backfill_fvk0d\": (0.0001 * kPa, 1000 * kPa),\n",
    "    \"Backfill_FrictionRatioShear\": (0.2, 1),\n",
    "    \"Backfill_ShearMaxTensileRatio\": (0.3, 0.8),\n",
    "    \n",
    "    \"Backfill_CohesionSlidingHor\": (0.0001 * kPa, 1000 * kPa),\n",
    "    \"Backfill_FrictionRatioSlidingHor\": (0.1, 1.2),\n",
    "})\n",
    "\n",
    "param_ranges[\"Foundation_Soil_Ehor\"] = (.01 * kPa, 0.5 * MPa)\n",
    "\n",
    "param_ranges[\"Damaged_Ehor\"] = (.01 * kPa, 0.5 * MPa)\n",
    "\n",
    "param_ranges = {\n",
    "    \"Damaged_Ehor\": (0.1 * MPa, 0.101 * MPa)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47b23c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = {\n",
    "    # (\"Masonry_Ehor\", \"Masonry_FmHor\"): .5,\n",
    "    # (\"Masonry_Ehor\", \"Masonry_FtmHor\"): 0.5,\n",
    "    # (\"Foundation_Ehor\", \"Foundation_FmHor\"): 0.6,\n",
    "    # (\"Backfill_Gd\", \"Backfill_Ehor\"): 0.4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c2170c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from build_scenarios import build_scenarios\n",
    "\n",
    "\n",
    "\n",
    "# param_ranges = {}\n",
    "n_scenarios = 4\n",
    "\n",
    "scenarios = build_scenarios(param_ranges, n_scenarios, \"NewAnalysis\", correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3885a71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "locations = [\"pier_1\", \"pier_2\"]\n",
    "materials = [\"Damaged\", \"Foundation_Soil\"]\n",
    "\n",
    "for s in scenarios:\n",
    "    s[\"Scour\"] = {\n",
    "        loc: random.choice(materials)\n",
    "        for loc in locations\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9c88dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios[0]['Scour'] = {\n",
    "    \"pier_1\": \"Foundation_Soil\",\n",
    "    \"pier_2\": \"Foundation_Soil\"\n",
    "}\n",
    "\n",
    "scenarios[1]['Scour'] = {\n",
    "    \"pier_1\": \"Damaged\",\n",
    "    \"pier_2\": \"Foundation_Soil\"\n",
    "}\n",
    "\n",
    "scenarios[2]['Scour'] = {\n",
    "    \"pier_1\": \"Foundation_Soil\",\n",
    "    \"pier_2\": \"Damaged\"\n",
    "}\n",
    "\n",
    "scenarios[3]['Scour'] = {\n",
    "    \"pier_1\": \"Damaged\",\n",
    "    \"pier_2\": \"Damaged\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884a8b4e",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed7baba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing_steps import prepare_model\n",
    "from run_scenario import run_scenario\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "def run_model(input_path, scenarios, timeout=360, max_workers=4):\n",
    "    \"\"\"Run all scenarios in parallel.\"\"\"\n",
    "    prepare_model(input_path)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        for i, scenario in enumerate(scenarios):\n",
    "            time.sleep(0.2)\n",
    "            futures.append(executor.submit(run_scenario, input_path, scenario, i, timeout))\n",
    "        for future in as_completed(futures):\n",
    "            try:\n",
    "                future.result()\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\nðŸ›‘ Program interrupted by user. Cancelling all remaining tasks...\")\n",
    "                executor.shutdown(wait=False, cancel_futures=True)\n",
    "                raise\n",
    "            except Exception as e:\n",
    "                print(f\"Error in one of the scenarios: {e}\")\n",
    "                time.sleep(0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858c8505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating mesh analysis\n",
      "Running mesh analysis\n",
      "Pre-processing: 1\n",
      "Copying: 1\n",
      "Pre-processing: 2\n",
      "Copying: 2\n",
      "Pre-processing: 3\n",
      "Copying: 3\n",
      "Updating materials: 1\n",
      "Updating materials: 2\n",
      "Updating materials: 3\n",
      "Updating foundation interfaces: 1\n",
      "Updating foundation interfaces: 3\n",
      "Updating foundation interfaces: 2\n",
      "Pre-processing finished: 3\n",
      "Pre-processing finished: 2\n",
      "Pre-processing finished: 1\n",
      "Processing: 3\n",
      "Processing: 1Processing: 2\n",
      "\n",
      "Running: 1 - NewAnalysis\n",
      "Running: 3 - NewAnalysis\n",
      "Running: 2 - NewAnalysis\n",
      "Pos-processing: 3\n",
      "Pre-processing finished: 3\n",
      "Pre-processing: 4\n",
      "Copying: 4\n",
      "Updating materials: 4\n",
      "Updating foundation interfaces: 4\n",
      "Pre-processing finished: 4\n",
      "Processing: 4\n",
      "Running: 4 - NewAnalysis\n",
      "â° Timeout: c:\\Users\\mbonatte\\Documents\\Coding\\histra-automation\\temp_dir\\Bridge_2_foundation_copy_1.hrx exceeded 180 seconds. Killing...\n",
      "Error in one of the scenarios: Command '['C:\\\\Program Files\\\\Gruppo Sismica\\\\HiStrA Bridges 2024.1.1\\\\SolverHistra.exe', 'run', 'c:\\\\Users\\\\mbonatte\\\\Documents\\\\Coding\\\\histra-automation\\\\temp_dir\\\\Bridge_2_foundation_copy_1.hrx', '-CloseWithoutAsk', 'true']' timed out after 180 seconds\n",
      "â° Timeout: c:\\Users\\mbonatte\\Documents\\Coding\\histra-automation\\temp_dir\\Bridge_2_foundation_copy_2.hrx exceeded 180 seconds. Killing...\n",
      "âŒ Solver returned an error.\n",
      "Model path:\n",
      " c:\\Users\\mbonatte\\Documents\\Coding\\histra-automation\\temp_dir\\Bridge_2_foundation_copy_4.hrx\n",
      "STDOUT:\n",
      " \n",
      "STDERR:\n",
      " \n",
      "Error in one of the scenarios: Command '['C:\\\\Program Files\\\\Gruppo Sismica\\\\HiStrA Bridges 2024.1.1\\\\SolverHistra.exe', 'run', 'c:\\\\Users\\\\mbonatte\\\\Documents\\\\Coding\\\\histra-automation\\\\temp_dir\\\\Bridge_2_foundation_copy_4.hrx', '-CloseWithoutAsk', 'true']' returned non-zero exit status 1.\n",
      "Error in one of the scenarios: Command '['C:\\\\Program Files\\\\Gruppo Sismica\\\\HiStrA Bridges 2024.1.1\\\\SolverHistra.exe', 'run', 'c:\\\\Users\\\\mbonatte\\\\Documents\\\\Coding\\\\histra-automation\\\\temp_dir\\\\Bridge_2_foundation_copy_2.hrx', '-CloseWithoutAsk', 'true']' timed out after 180 seconds\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "INPUT_FILE = r\"Bridge_2_foundation.hrx\"\n",
    "INPUT_FILE = os.path.abspath(INPUT_FILE)\n",
    "\n",
    "directory = os.path.dirname(INPUT_FILE)\n",
    "\n",
    "# with tempfile.TemporaryDirectory(prefix=\"histra_run_\", dir=directory) as temp_dir:\n",
    "#     input_copy = os.path.join(temp_dir, os.path.basename(INPUT_FILE))\n",
    "#     shutil.copy2(INPUT_FILE, input_copy)\n",
    "#     run_model(input_copy, scenarios, timeout=360, max_workers=3)\n",
    "\n",
    "\n",
    "temp_dir = os.path.join(directory, \"temp_dir\")\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "input_copy = os.path.join(temp_dir, os.path.basename(INPUT_FILE))\n",
    "shutil.copy2(INPUT_FILE, input_copy)\n",
    "run_model(input_copy, scenarios, timeout=360, max_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9319fe18",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Outputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mscenarios\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOutputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Outputs'"
     ]
    }
   ],
   "source": [
    "scenarios[0]['Outputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d08c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d098711",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc09e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing data\n",
    "try:\n",
    "    with open(\"scenarios_results.json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    data = [] \n",
    "\n",
    "print(len(data))\n",
    "# Append the new data\n",
    "data.extend(scenarios)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259e1ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_results import flat_data\n",
    "from filter_data import normalized_distance_filter\n",
    "\n",
    "df = flat_data(data)\n",
    "\n",
    "df = df.drop_duplicates(subset=\"_source_index\")\n",
    "\n",
    "cols = [\"Damaged_Ehor\",\n",
    "        \"Masonry_w\", \"Masonry_Ehor\", \"Masonry_FtmHor\", \"Masonry_FmHor\"]\n",
    "\n",
    "df_filtered, kept_idx, removed_idx, clusters = normalized_distance_filter(\n",
    "    df,\n",
    "    cols=cols, \n",
    "    scale=\"minmax\", #zscore or minmax\n",
    "    eps=0.000001,\n",
    "    keep=\"first\"\n",
    ")\n",
    "\n",
    "print(f\"Kept {len(kept_idx)} of {len(df)} rows; removed {len(removed_idx)} near-duplicates.\")\n",
    "\n",
    "# Use kept indices to filter the original JSON list\n",
    "\n",
    "source_indices = df.loc[kept_idx, \"_source_index\"].unique().tolist()\n",
    "filtered_data = [data[i] for i in source_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649bbdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"scenarios_results.json\", \"w\") as f:\n",
    "    json.dump(filtered_data, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
